{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing preview\n",
      "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
      "Id                                                                        \n",
      "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
      "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
      "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
      "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
      "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
      "\n",
      "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
      "Id                                    ...                                       \n",
      "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
      "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
      "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
      "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
      "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
      "\n",
      "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
      "Id                                                                         \n",
      "619         260         0        0       7    2007      New       Partial  \n",
      "871           0         0        0       8    2009       WD        Normal  \n",
      "93            0         0        0       8    2009       WD        Normal  \n",
      "818           0         0        0       7    2008       WD        Normal  \n",
      "303           0         0        0       1    2006       WD        Normal  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# NOTE THIS TIME USING ALL NUMERICAL VALUES, ACCURACY SHOULD INCREASE\n",
    "#------------------------------------------------------------------------------------------\n",
    "# PROGRAM DESCRIPTION \n",
    "#\n",
    "# THIS PROGRAM DEALS WITH CATAGORICAL VALUES I.E. TEXT\n",
    "# \n",
    "# OPTION 1: DROP ALL COLUMNS WITH ['object']\n",
    "# OPTION 2: LABEL ENCODING\n",
    "# OPTION 3: ONE HOT ENCODING\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "# FIT MODEL\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the train_test_split function and uncomment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# PREP: REMOVE ROWS MISSING TARGET, USE ONLY NUMBERS & SPLIT\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with MISSING TARGET, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True) # removes sales price from training frame\n",
    "\n",
    "\n",
    "# FULL DROP OUT BUT KEEPING MOST CATAGORICAL ROWS \n",
    "# DROP MISSING VALUES (NO IMPUTATION)\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)          # DROP TRAIN\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)     # DROP TEST\n",
    "\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "print('printing preview')\n",
    "print(X_train.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# DEFINE OPTIMISER SCORING FUNCTION\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# GET ALL CATAGORICAL COLUMSN\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\n#------------------------------------------------------------------------------------------\\n# OPTION 1: DROP ALL CATAGORICAL \\n#------------------------------------------------------------------------------------------\\n\\n\\ndrop_X_train = X_train.select_dtypes(exclude=[\\'object\\'])\\ndrop_X_valid = X_valid.select_dtypes(exclude=[\\'object\\'])\\nprint(\\'Final trainx shape is :\\' + str(drop_X_train.shape))\\nprint(\\'Final validx shape is :\\' + str(drop_X_valid.shape))\\nprint(\\'\\')\\nprint(\"MAE from Approach 1 (Drop categorical variables):\")\\nprint(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\\n\\n\\n#------------------------------------------------------------------------------------------\\n# OPTION 2: LABEL ENCODING\\n#------------------------------------------------------------------------------------------\\n\\nprint(\\'first look at values in condition 2\\')\\nprint(\"Unique values in \\'Condition2\\' column in training data:\", X_train[\\'Condition2\\'].unique())\\nprint(\"\\nUnique values in \\'Condition2\\' column in validation data:\", X_valid[\\'Condition2\\'].unique())\\nprint(\\'\\')\\nprint(\\'we need to drop unmatching columns\\')\\n\\n\\n\\n# GET GOOD COLUMN NAMES\\ngood_label_cols = [col for col in object_cols if \\n                   set(X_train[col]) == set(X_valid[col])]\\n        \\n# GET BAD COLUMN NAMES\\nbad_label_cols = list(set(object_cols)-set(good_label_cols))\\n\\n      \\nprint(\\'Categorical columns that will be label encoded:\\', good_label_cols)\\nprint(\\'\\nCategorical columns that will be dropped from the dataset:\\', bad_label_cols)\\n\\n\\n\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n# Drop categorical columns that will not be encoded\\nlabel_X_train = X_train.drop(bad_label_cols, axis=1)\\nlabel_X_valid = X_valid.drop(bad_label_cols, axis=1)\\n\\n# Apply label encoder\\nlabel_encoder = LabelEncoder()\\n\\n# Transform each of the xtrain/xvalid columns that match the goodlabels column\\nfor col in set(good_label_cols):\\n    label_X_train[col] = label_encoder.fit_transform(X_train[col])\\n    label_X_valid[col] = label_encoder.transform(X_valid[col])\\n    \\nprint(\\'Final trainx shape is :\\' + str(label_X_train.shape))\\nprint(\\'Final validx shape is :\\' + str(label_X_valid.shape))\\nprint(\\'\\')\\nprint(\"MAE from Approach 2 (Label Encoding):\") \\nprint(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"   \n",
    "#------------------------------------------------------------------------------------------\n",
    "# OPTION 1: DROP ALL CATAGORICAL \n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "print('Final trainx shape is :' + str(drop_X_train.shape))\n",
    "print('Final validx shape is :' + str(drop_X_valid.shape))\n",
    "print('')\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# OPTION 2: LABEL ENCODING\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('first look at values in condition 2')\n",
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())\n",
    "print('')\n",
    "print('we need to drop unmatching columns')\n",
    "\n",
    "\n",
    "\n",
    "# GET GOOD COLUMN NAMES\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# GET BAD COLUMN NAMES\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "\n",
    "      \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform each of the xtrain/xvalid columns that match the goodlabels column\n",
    "for col in set(good_label_cols):\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    \n",
    "print('Final trainx shape is :' + str(label_X_train.shape))\n",
    "print('Final validx shape is :' + str(label_X_valid.shape))\n",
    "print('')\n",
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Street', 2), ('Utilities', 2), ('CentralAir', 2), ('LandSlope', 3), ('PavedDrive', 3), ('LotShape', 4), ('LandContour', 4), ('ExterQual', 4), ('KitchenQual', 4), ('MSZoning', 5), ('LotConfig', 5), ('BldgType', 5), ('ExterCond', 5), ('HeatingQC', 5), ('Condition2', 6), ('RoofStyle', 6), ('Foundation', 6), ('Heating', 6), ('Functional', 6), ('SaleCondition', 6), ('RoofMatl', 7), ('HouseStyle', 8), ('Condition1', 9), ('SaleType', 9), ('Exterior1st', 15), ('Exterior2nd', 16), ('Neighborhood', 25)]\n",
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'Exterior1st', 'Exterior2nd']\n",
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('saving to submission file ')\\n\\n# Save test predictions to file\\noutput = pd.DataFrame({'Id': X_test.index,\\n                       'SalePrice': preds_test})\\noutput.to_csv('submission.csv', index=False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#  OPTION 3: ONE HOT ENCODING\n",
    "#  Get unique value count for catagorical columsn\n",
    "#  One hot encode all below <10\n",
    "#  Drop any above >10 \n",
    "#  Or label encode (best not to do this, incase of disparity)\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Investigating cardinality\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "\n",
    "# ENCODE ONLY IF LESS THAN 10 UNIQUE VALUES I.E. CARDINALITY < 10\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# STORE THE REMAINING COLUMN NAMES TO BE LABEL ENCODED\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "#OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "# This also saves us the hassle of dropping columns \n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# TEST DATA PREP\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# SAVE\n",
    "#------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "print('saving to submission file ')\n",
    "\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
